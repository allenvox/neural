# Fraud Detection bachelor work
[PDF report](../docs/report.pdf)
### Ответы на типовые вопросы
#### Вопрос 1: Почему вы выбрали ROC-AUC как основную метрику, а не F1-score, который часто используется для несбалансированных данных? Не кажется ли вам, что F1-score был бы более подходящим?

**Ответ**:  
Спасибо за вопрос! ROC-AUC выбрана как основная метрика из-за сильного дисбаланса в датасете Credit Card Fraud Detection (0.17% мошеннических транзакций). ROC-AUC оценивает способность модели различать классы независимо от порога классификации, что важно для нашей задачи, где порог может меняться в зависимости от требований банка. Например, ROC-AUC 0.9998 для многослойного перцептрона показывает почти идеальное разделение классов. F1-score (0.9422 для логистической регрессии) тоже полезен, так как балансирует Precision и Recall, но он зависит от порога, что может искажать сравнение моделей. Поэтому F1-score я использовал как дополнительную метрику для тонкой настройки, а ROC-AUC — для объективного анализа. Кроме того, в задаче обнаружения мошенничества важно учитывать оба типа ошибок (пропуск мошенничества и ложные срабатывания), и ROC-AUC лучше отражает этот компромисс.

---

#### Вопрос 2: Вы использовали SMOTE для балансировки данных. Но синтетические данные могут искажать реальное распределение. Как это повлияло на результаты, и рассматривали ли вы другие подходы?

**Ответ**:  
Действительно, SMOTE создаёт синтетические данные, что может влиять на распределение, и я учёл это ограничение. В работе я сравнивал SMOTE с другими методами: Undersampling (уменьшение мажоритарного класса) и перевзвешивание (увеличение веса миноритарного класса в функции потерь). SMOTE показал лучшие результаты — Precision вырос более чем в 2 раза по сравнению с альтернативами, что подтверждает его эффективность для наших данных. Однако я осознаю, что синтетические данные могут не полностью отражать реальные паттерны, особенно если мошеннические транзакции имеют сложные зависимости. Для минимизации искажений я масштабировал признаки и использовал кросс-валидацию. В дальнейшем рекомендую тестировать модели на дополнительных датасетах или применять методы, такие как генерация данных через GAN, чтобы улучшить качество синтетических примеров.

---

#### Вопрос 3: Многослойный перцептрон показал лучшие результаты (ROC-AUC 0.9998), но он сложен в интерпретации. Как вы предлагаете внедрять такую модель в реальную банковскую систему, где важна прозрачность решений?

**Ответ**:  
Спасибо за вопрос! Действительно, многослойный перцептрон сложен для интерпретации, но я применил методы SHAP и LIME для объяснения его решений. Например, LIME показал, что признаки V14 и V12 имеют наибольший вклад в предсказания мошенничеств, с конкретными диапазонами, такими как (0.50 < V14 <= 0.80). Для внедрения в банковскую систему я предлагаю интегрировать такие объяснения в интерфейс системы мониторинга: оператор будет видеть не только предсказание, но и ключевые признаки, повлиявшие на решение, что повысит доверие. Также можно комбинировать перцептрон с более интерпретируемыми моделями, например, логистической регрессией, для проверки решений. Наконец, высокая точность (ROC-AUC 0.9998) и Recall 1.00 позволяют минимизировать риски пропуска мошенничеств, что оправдывает использование модели, если интерпретируемость обеспечена через SHAP и LIME.

---

#### Вопрос 4: Вы упомянули, что логистическая регрессия показала ROC-AUC 0.9848, что довольно близко к перцептрону (0.9998). Почему бы не использовать более простую модель, которая легче интерпретируется?

**Ответ**:  
Хороший вопрос! Логистическая регрессия действительно проще и интерпретируема, и её ROC-AUC 0.9848 — высокий показатель. Однако разница в 0.015 с перцептроном (0.9998) значима в нашей задаче. В датасете 492 мошеннические транзакции, и улучшение ROC-AUC на 0.015 эквивалентно обнаружению дополнительных 7–8 случаев, что может сэкономить банку значительные средства. Кроме того, Recall у логистической регрессии ниже (0.9046 против 1.00 у перцептрона), что означает больше пропущенных мошенничеств. Для банков это критично, так как пропуск даже одного случая может привести к большим потерям. Хотя логистическая регрессия хороша для начального анализа, я выбрал перцептрон для финального решения, дополнив его методами интерпретации (SHAP и LIME), чтобы компенсировать сложность.

---

#### Вопрос 5: В заключении вы упомянули, что не охватили самые передовые методы, такие как трансформеры. Почему вы их не использовали, и насколько это ограничение влияет на результаты?

**Ответ**:  
Спасибо за вопрос! Я действительно не использовал трансформеры и свёрточные сети, так как в рамках бакалаврской работы стремился сосредоточиться на классических и ансамблевых методах, таких как логистическая регрессия, деревья и перцептрон, чтобы изучить их основы и сравнить их производительность. Кроме того, трансформеры требуют больших вычислительных ресурсов и объёма данных, а мой датасет (284807 транзакций) относительно небольшой для таких моделей. Моя конфигурация (RTX 3060, 16 ГБ RAM) справилась с текущими моделями, но для трансформеров могла потребоваться оптимизация. Ограничение в том, что трансформеры могли бы уловить более сложные зависимости, возможно, улучшив ROC-AUC выше 0.9998. Однако текущие результаты (перцептрон с ROC-AUC 0.9998) уже близки к идеалу, и для практического применения в банке их достаточно. В будущем я планирую протестировать трансформеры на объединённых датасетах, чтобы оценить их эффективность.
